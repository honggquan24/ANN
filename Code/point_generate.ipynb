{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liraries in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Library code generate points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spiral:\n",
    "    def __init__(self, n_points, n_classes, n_dimensions):        \n",
    "        #generating a randomized data\n",
    "        self.N = n_points # number of points per class\n",
    "        self.D = n_dimensions # dimension\n",
    "        self.K = n_classes # number of classes\n",
    "        self.P = np.zeros((self.N*self.K,self.D)) # data matrix (each row = single example)\n",
    "        self.L = np.zeros(self.N*self.K, dtype='uint8') # class labels\n",
    "        for j in range(self.K):\n",
    "            ix = range(self.N*j,self.N*(j+1))\n",
    "            r = np.linspace(0.0,1,self.N) # radius\n",
    "            t = np.linspace(j*4,(j+1)*4,self.N)  + np.random.randn(self.N)*0.2 # theta\n",
    "            self.P[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "            self.L[ix] = j\n",
    "\n",
    "    def generate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line:\n",
    "    def __init__(self, n_points, n_classes, n_dimensions):        \n",
    "        #generating a randomized data\n",
    "        self.N = n_points # number of points per class\n",
    "        self.D = n_dimensions # dimension\n",
    "        self.K = n_classes # number of classes\n",
    "        self.P = np.zeros((self.N*self.K,self.D)) # data matrix (each row = single example)\n",
    "        self.L = np.zeros(self.N*self.K, dtype='uint8') # class labels\n",
    "        for j in range(self.K):\n",
    "            a = 2*(j-1) \n",
    "            b = np.zeros(self.N)\n",
    "            for i in range(len(b)):\n",
    "                b[i] = (j-2)*2 + np.random.randn(1)\n",
    "            ix = range(self.N*j,self.N*(j+1))\n",
    "            t = np.linspace(-10,10,self.N)\n",
    "            if (self.D == 2):\n",
    "                self.P[ix] = np.c_[t, a*t + b]\n",
    "                self.L[ix] = j\n",
    "\n",
    "    def generate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Circle:\n",
    "    def __init__(self, n_points, n_classes, n_dimensions):        \n",
    "        #generating a randomized data\n",
    "        self.N = n_points # number of points per class\n",
    "        self.D = n_dimensions # dimension\n",
    "        self.K = n_classes # number of classes\n",
    "        self.P = np.zeros((self.N*self.K,self.D)) # data matrix (each row = single example)\n",
    "        self.L = np.zeros(self.N*self.K, dtype='uint8') # class labels\n",
    "        for j in range(self.K):\n",
    "            ix = range(self.N*j,self.N*(j+1))\n",
    "            r = np.zeros(self.N)\n",
    "            for i in range(len(r)):\n",
    "                r[i] = (j+1)*2 + np.random.randn(1)*0.5\n",
    "            t = np.linspace(0,2*3.1415,self.N)  + np.random.randn(self.N)*0.2 # theta\n",
    "            self.P[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "            self.L[ix] = j\n",
    "\n",
    "    def generate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zone:\n",
    "    def __init__(self, n_points, n_classes, n_dimensions):        \n",
    "        #generating a randomized data\n",
    "        self.N = n_points # number of points per class\n",
    "        self.D = n_dimensions # dimension\n",
    "        self.K = n_classes # number of classes\n",
    "        self.P = np.zeros((self.N*self.K,self.D)) # data matrix (each row = single example)\n",
    "        self.L = np.zeros(self.N*self.K, dtype='uint8') # class labels\n",
    "        pi = 3.1415\n",
    "        for j in range(self.K):\n",
    "            theta = j*(2*pi)/self.K\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            ix = range(self.N*j,self.N*(j+1))\n",
    "            r = np.zeros(self.N)\n",
    "            for i in range(len(r)):\n",
    "                r[i] = np.random.randn(1)*0.5\n",
    "            t = np.linspace(0,2*3.1415,self.N)  + np.random.randn(self.N)*0.2 # theta\n",
    "            self.P[ix] = np.c_[a + r*np.sin(t), b + r*np.cos(t)]\n",
    "            self.L[ix] = j\n",
    "\n",
    "    def generate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zone 3D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zone_3D:\n",
    "    def __init__(self, n_points, n_classes, n_dimensions, centers):        \n",
    "        #generating a randomized data\n",
    "        self.N = n_points # number of points per class\n",
    "        self.D = n_dimensions # dimension\n",
    "        self.K = n_classes # number of classes\n",
    "        self.P = np.zeros((self.N*self.K,self.D)) # data matrix (each row = single example)\n",
    "        self.L = np.zeros(self.N*self.K, dtype='uint8') # class labels\n",
    "        pi = 3.1415\n",
    "        for j in range(self.K):\n",
    "            center_j = centers[j]\n",
    "            theta = j*(2*pi)/self.K\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            ix = range(self.N*j,self.N*(j+1))\n",
    "            R = np.zeros(self.N)\n",
    "            k = np.zeros(self.N)\n",
    "            r = np.zeros(self.N)\n",
    "            g = np.linspace(0,2*3.1415,self.N)  #+ np.random.randn(self.N)*0.2 # gamma\n",
    "            t = np.linspace(0,2*3.1415,self.N)  #+ np.random.randn(self.N)*0.2 # theta\n",
    "\n",
    "            for i in range(len(R)):\n",
    "                R[i] = np.random.randn(1)*2\n",
    "                k[i] = R[i] * np.sin(g[i])\n",
    "                r[i] = R[i] * np.cos(g[i])\n",
    "\n",
    "            self.P[ix] = np.c_[center_j[0] + r*np.sin(t), center_j[1] + r*np.cos(t), center_j[2] + k]\n",
    "            self.L[ix] = j\n",
    "\n",
    "    def generate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loss code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    # Calculate the data and regulazation losses given\n",
    "    # the output and the ground truth values\n",
    "    def calculate(self,output,y):\n",
    "        #Calculate sample losses:\n",
    "        sample_losses = self.forward(output,y)\n",
    "        #Calculate mean loss:\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        #Return loss:\n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation softmax loss caterical cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax_Loss_CategoricalCrossEntropy():\n",
    "\n",
    "    # Create activation and loss function object\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_SoftMax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, y_true):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "\n",
    "        # Calculate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "    \n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "        # number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        #if labels are one-hot encoded, turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis =1)\n",
    "\n",
    "        # Copy to safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "        # Calculate gradients\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        # Normalize gradients\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross entropy loss class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossentropy(Loss): \n",
    "\n",
    "    # Forward Pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # Clip both sides to not drag mean toward any values\n",
    "        y_pred_clipped = np.clip(y_pred,1e-7,1-1e-7) #1e-7 is added to avoid division by 0\n",
    "\n",
    "        # Probabilities for target values only if categorical labels\n",
    "\n",
    "        if len(y_true.shape) == 1: # The label array is 1D [0 0 ... 1 ... 0 0]\n",
    "            correct_confidence = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]    # Extract the correct confidence in y_pred by referencing to y_true vector\n",
    "        elif len(y_true.shape) == 2: # The label array is 2D (vector form: [[0 0 0 ... 1 0 0 ... 0],[0 0 0 ... 1 0 0 ... 0],[0 0 0 ... 1 0 0 ... 0]])\n",
    "            correct_confidence = np.sum(\n",
    "                y_pred_clipped*y_true,\n",
    "                axis = 1\n",
    "            )\n",
    "\n",
    "        # Losses calculation\n",
    "        negative_log_likelihoods = -np.log(correct_confidence)\n",
    "        return negative_log_likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Activation code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Linear:\n",
    "    # Forward Pass\n",
    "    def forward(self,inputs):\n",
    "        #Calculate output values from input\n",
    "        self.output = inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Sigmoid:\n",
    "    # Forward Pass\n",
    "    def forward(self,inputs):\n",
    "        #Calculate output values from input\n",
    "        self.output = 1 / (1 + np.exp(-inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    #Forward Pass\n",
    "    def forward(self,inputs):\n",
    "        #Calculate output values from input\n",
    "        self.output = np.maximum(0,inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_SoftMax:\n",
    "\n",
    "    #Forward pass:\n",
    "    def forward(self,inputs):\n",
    "\n",
    "        #Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis = 1,keepdims=True))\n",
    "        self.exp_values = exp_values\n",
    "\n",
    "        #Normalized them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis = 1, keepdims=True)\n",
    "\n",
    "        self.output = probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
