{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "Binary \\space Step \\space Function (x) = \n",
    "\\begin{cases}\n",
    "1 \\quad if \\quad \\sum_{i=1}^{m} w_i x_i + b \\ge threshold \\\\\n",
    "0 \\quad if \\quad \\sum_{i=1}^{m} w_i x_i + b \\lt threshold \\\\\n",
    "\\end{cases}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "ReLU (x) = \n",
    "\\begin{cases}\n",
    "0 \\quad if \\quad x \\lt 0 \\\\\n",
    "1 \\quad if \\quad x \\ge  x\n",
    "\\end{cases}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "Sigmoid (x) = \n",
    "\n",
    "\\frac{1}{1 + e^{-x}} \\in [0, 1]\n",
    "\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "Tanh (x) = \n",
    "\n",
    "\\frac{ e^{x} - e^{-x}  }{ e^{x} + e^{-x}} \\in [-1, 1]\n",
    "\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivative / Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f'(x) = lim_{\\triangle x \\rightarrow 0} \\frac { f(x+\\triangle) - f(x) } {\\triangle x} \\\\ \n",
    "y' = lim_{\\triangle x \\rightarrow 0} \\frac { \\triangle y } {\\triangle x} \\\\\n",
    "\\frac {dy} {dx} = lim_{\\triangle x \\rightarrow 0} \\frac { \\triangle y } {\\triangle x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla f = [ \\frac{\\partial f}{\\partial x} , \\frac{\\partial f}{\\partial y} , \\frac{\\partial f}{\\partial z} ]  \\\\ \n",
    "\\nabla f = [ \\frac{\\partial f}{\\partial x}i + \\frac{\\partial f}{\\partial y}j + \\frac{\\partial f}{\\partial z}k ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direction of increase of function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "D_{\\vec{b}}f = \\nabla f.\\vec{b} = \\|  \\nabla f \\| \\| b \\| \\cos{\\theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Decent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\vec{x_0} = (x_0, y_0) \\\\\n",
    "\\vec{x_{n+1}} = \\vec{x_n} - \\eta \\nabla f \\vec{x_n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_{j, i}$ là trọng số kết nối từ ngõ vào neural thứ i đến neural thứ j ở lớp sau nó\n",
    "$$\n",
    "a_j = \\sum_{i=1}^{n}x_i w_{j,i} + b_j \\\\\n",
    "o_j = \\sigma (a_j) = \\frac{1}{1 + e^{-a_j}} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - (ax_i+b)^2) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J = Costfunction() \\\\\n",
    "w = w - \\eta\\frac{\\partial J}{\\partial w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train new neural network with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "a_j = \\sum_{i=1}^{20}x_i w_{j, i} + b_j \\\\\n",
    "o_j = \\sigma(a_j)=\\frac{1}{1+e^{-a_j}}  \\\\\n",
    "J = \\frac{1}{5} \\sum_{t=1}^{5} \\sum_{k=1}^{5} (y_k^t - o_k^t)^2 \\space trong \\ đó \\ k: \\ là \\ số \\ ngõ \\ ra, \\ t \\ là \\ số \\ mẫu \\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Character matrix and target labels\n",
    "char = np.matrix([\n",
    "    [0, 0, 1, 0,\n",
    "     0, 1, 1, 0,\n",
    "     0, 0, 1, 0,\n",
    "     0, 0, 1, 0,\n",
    "     1, 1, 1, 1], \n",
    "    [1, 1, 1, 1,\n",
    "     0, 0, 0, 1,\n",
    "     1, 1, 1, 1,\n",
    "     1, 0, 0, 0,\n",
    "     1, 1, 1, 1],\n",
    "    [1, 1, 1, 1,\n",
    "     0, 0, 0, 1,\n",
    "     1, 1, 1, 1,\n",
    "     0, 0, 0, 1,\n",
    "     1, 1, 1, 1],\n",
    "    [1, 0, 0, 1,\n",
    "     1, 0, 0, 1,\n",
    "     1, 1, 1, 1,\n",
    "     0, 0, 0, 1,\n",
    "     0, 0, 0, 1],\n",
    "    [1, 1, 1, 1,\n",
    "     1, 0, 0, 0,\n",
    "     1, 1, 1, 1,\n",
    "     0, 0, 0, 1,\n",
    "     1, 1, 1, 1]\n",
    "], dtype=np.int8)\n",
    "\n",
    "target = np.matrix([\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 1],\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function for sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.1  # Learning rate\n",
    "epochs = 100  # Number of epochs\n",
    "\n",
    "# Weight initialization\n",
    "w = np.matrix(np.random.uniform(-0.1, 0.1, (5, 20)))\n",
    "\n",
    "# To track cost function (J) values over epochs\n",
    "J = np.zeros(epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    dJ_dw = np.zeros_like(w)  # Initialize gradient to zero for each epoch\n",
    "    total_cost = 0  # Initialize total cost for each epoch\n",
    "    \n",
    "    for sample in range(5):  # Loop over all samples\n",
    "        X = char[sample, :]  # Input character sample\n",
    "        y = target[sample, :]  # Corresponding target\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = sigmoid(np.dot(X, w.T))  # Predicted output\n",
    "        \n",
    "        # Compute error and gradients\n",
    "        error = y - y_pred\n",
    "        delta = np.multiply(np.multiply(error, y_pred), (1 - y_pred))  # Derivative of sigmoid\n",
    "        dJ_dw += delta.T * X  # Accumulate gradients\n",
    "        \n",
    "        # Cost (Mean Squared Error for this sample)\n",
    "        total_cost += np.mean(np.power(error, 2))\n",
    "    \n",
    "    # Update weights after processing all samples\n",
    "    w += alpha * dJ_dw / 5  # Gradient step, averaged over the samples\n",
    "    \n",
    "    # Store the cost for this epoch\n",
    "    J[epoch] = total_cost / 5\n",
    "\n",
    "# Plot the cost function over epochs\n",
    "plt.plot(J)\n",
    "plt.ylabel('Cost Function (J)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Cost Function Over Epochs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation and gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from abc import abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt('mnist_train.csv', delimiter= ',')\n",
    "test_data = np.loadtxt('mnist_test.csv', delimiter= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[:, 1:]\n",
    "X_test = test_data[:, 1:]\n",
    "\n",
    "y_train = train_data[:, 0]\n",
    "y_test = test_data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "class ActivationFunction:\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_derivative(x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        # Đảm bảo tính ổn định số học\n",
    "        exp_values = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, *, input_size: int, hidden_layer: list,\n",
    "                  output_size: int, learning_rate: float, optimizer: list,\n",
    "                    activation_functions: list, input: np.array, target= np.array) -> None:\n",
    "        self.input_size = input_size # input\n",
    "        self.output_size = output_size # output\n",
    "        self.hidden_layer = hidden_layer # hidden layer\n",
    "        self.learning_rate = learning_rate # learning rate\n",
    "        self.activation_functions = activation_functions # list activation function\n",
    "        self.optimizer = optimizer # optimizer\n",
    "        self.input = input # input\n",
    "        self.target = target # target\n",
    "        self.len = len(input) # len input (m)\n",
    "\n",
    "        # size of layer\n",
    "        self.layer_size = [self.input_size] + list(self.hidden_layer) + [self.output_size]\n",
    "        print(f'layer_size: \\n {self.layer_size}, len: {len(self.layer_size)}')\n",
    "\n",
    "        # output of layer after feedforward\n",
    "        self.list_output_in_layer= [0]*(len(self.layer_size) - 1 )\n",
    "\n",
    "        # init weight and bias\n",
    "        self.matrices_weights = [0]*(len(self.layer_size) - 1 )\n",
    "        self.matrices_biases = [0]*(len(self.layer_size) - 1 )\n",
    "        for idx in range(len(self.layer_size) - 1):\n",
    "            # init weight \n",
    "            # matrix_weight = np.random.randn(self.layer_size[idx], self.layer_size[idx+1]) / 10\n",
    "            matrix_weight = np.ones((self.layer_size[idx], self.layer_size[idx+1]))\n",
    "            self.matrices_weights[idx] = matrix_weight\n",
    "            print(f'matrix_weight {idx}: \\n {matrix_weight}, shape: {matrix_weight.shape}')\n",
    "\n",
    "            # init bias\n",
    "            # matrix_bias = np.random.randn(1, self.layer_size[idx + 1]) / 10\n",
    "            matrix_bias = np.ones((1, self.layer_size[idx + 1])) / 10\n",
    "            self.matrices_biases[idx] = matrix_bias\n",
    "            print(f'matrix_bias {idx}: \\n {matrix_bias}, shape: {matrix_bias.shape}')\n",
    "\n",
    "    def feed_forward(self):\n",
    "        \"\"\"Performs feedforward calculation for the network.\"\"\"\n",
    "        input_array = self.input\n",
    "        \n",
    "        for idx, (weight, bias) in enumerate(zip(self.matrices_weights, self.matrices_biases)):\n",
    "            # print(f'optimizer at layer {idx}= {self.layer_activation_fn[idx]}')\n",
    "            # print(idx, (weight, bias))\n",
    "            input_array = input_array @ weight + bias  # Matrix multiplication and bias addition\n",
    "            vector_activated = input_array\n",
    "\n",
    "            self.list_output_in_layer[idx] = vector_activated\n",
    "            print(f'vector_activated {idx}: \\n {vector_activated}, shape: {vector_activated.shape}')\n",
    "\n",
    "        return vector_activated\n",
    "    \n",
    "    def cal_error_layer(self):\n",
    "        self.error_layer[-1] = (self.target - self.list_vectors_layer[-1])*self.list_vectors_layer[-1]*(1 - self.list_vectors_layer[-1])\n",
    "        # print(self.error_layer[-1])\n",
    "\n",
    "        for idx, _ in enumerate(reversed(self.matrices_weights)):\n",
    "            reverse_i = len(self.matrices_weights) - 1 - idx\n",
    "            if reverse_i == len(self.matrices_weights) - 1:\n",
    "                self.error_layer[-1] = (self.target - self.list_vectors_layer[-1])*self.list_vectors_layer[-1]*(1 - self.list_vectors_layer[-1])\n",
    "            else:\n",
    "                self.error_layer[reverse_i] = self.error_layer[reverse_i + 1] @ self.matrices_weights[reverse_i + 1].T\n",
    "                # print(reverse_i + 1)\n",
    "\n",
    "                # print(self.error_layer[reverse_i + 1].shape)\n",
    "                # print(self.matrices_weights[reverse_i + 1].T.shape)\n",
    "\n",
    "    def back_prop(self):\n",
    "\n",
    "        for idx, matrix in enumerate(reversed(self.matrices_weights)):\n",
    "            reverse_i = len(self.matrices_weights) - 1 - idx\n",
    "            print(reverse_i)\n",
    "\n",
    "            len_ = self.error_layer[reverse_i].shape[1]\n",
    "            print(len_)\n",
    "\n",
    "            predict_ = self.list_vectors_layer[reverse_i].reshape(-1, 1).repeat(len_, 1)\n",
    "            print(predict_)\n",
    "\n",
    "            self.matrices_weights[reverse_i] += self.learning_rate * self.error_layer[reverse_i] * predict_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_size: \n",
      " [2, 1, 1], len: 3\n",
      "matrix_weight 0: \n",
      " [[1.]\n",
      " [1.]], shape: (2, 1)\n",
      "matrix_bias 0: \n",
      " [[0.1]], shape: (1, 1)\n",
      "matrix_weight 1: \n",
      " [[1.]], shape: (1, 1)\n",
      "matrix_bias 1: \n",
      " [[0.1]], shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "layer_activation_fn = ['ReLu', 'ReLu', 'Softmax']\n",
    "neural = NeuralNetwork(input_size= 2, hidden_layer= (1,), output_size= 1, learning_rate= 2, optimizer= 'str',\n",
    "                       activation_functions= layer_activation_fn, input= 2*np.ones((1, 2)), target= np.zeros((1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_activated 0: \n",
      " [[4.1]], shape: (1, 1)\n",
      "vector_activated 1: \n",
      " [[4.2]], shape: (1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.2]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural.feed_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat GPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 119\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Gán nhãn mục tiêu (one-hot encoding)\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m--> 119\u001b[0m     \u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Khởi tạo và huấn luyện mạng\u001b[39;00m\n\u001b[0;32m    122\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_size, hidden_layers, output_size, learning_rate, activation_functions, inputs, targets)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "class ActivationFunction:\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_derivative(x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        # Đảm bảo tính ổn định số học\n",
    "        exp_values = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_layers, output_size, learning_rate, activation_functions, inputs, targets):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation_functions = activation_functions\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.num_samples = len(inputs)\n",
    "\n",
    "        # Xây dựng kiến trúc mạng\n",
    "        self.layer_sizes = [self.input_size] + list(self.hidden_layers) + [self.output_size]\n",
    "\n",
    "        # Khởi tạo trọng số và bias\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for idx in range(len(self.layer_sizes) - 1):\n",
    "            weight_matrix = np.random.randn(self.layer_sizes[idx], self.layer_sizes[idx + 1]) / np.sqrt(self.layer_sizes[idx])\n",
    "            bias_vector = np.zeros((1, self.layer_sizes[idx + 1]))\n",
    "            self.weights.append(weight_matrix)\n",
    "            self.biases.append(bias_vector)\n",
    "\n",
    "    def feed_forward(self):\n",
    "        \"\"\"Thực hiện tính toán feedforward.\"\"\"\n",
    "        self.activations = [self.inputs]\n",
    "        self.pre_activations = []\n",
    "        for idx in range(len(self.weights)):\n",
    "            z = np.dot(self.activations[-1], self.weights[idx]) + self.biases[idx]\n",
    "            self.pre_activations.append(z)\n",
    "            # Áp dụng hàm kích hoạt\n",
    "            if self.activation_functions[idx] == 'relu':\n",
    "                a = ActivationFunction.relu(z)\n",
    "            elif self.activation_functions[idx] == 'softmax':\n",
    "                a = ActivationFunction.softmax(z)\n",
    "            else:\n",
    "                raise ValueError(f\"Hàm kích hoạt không được hỗ trợ: {self.activation_functions[idx]}\")\n",
    "            self.activations.append(a)\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def back_propagate(self):\n",
    "        \"\"\"Thực hiện backpropagation và cập nhật trọng số và bias.\"\"\"\n",
    "        deltas = [0] * len(self.weights)\n",
    "        # Tính delta cho lớp output\n",
    "        if self.activation_functions[-1] == 'softmax':\n",
    "            delta = self.activations[-1] - self.targets\n",
    "        else:\n",
    "            delta = (self.activations[-1] - self.targets) * ActivationFunction.relu_derivative(self.pre_activations[-1])\n",
    "        deltas[-1] = delta\n",
    "\n",
    "        # Lan truyền ngược lỗi\n",
    "        for idx in reversed(range(len(deltas) - 1)):\n",
    "            if self.activation_functions[idx] == 'relu':\n",
    "                derivative = ActivationFunction.relu_derivative(self.pre_activations[idx])\n",
    "            else:\n",
    "                derivative = 1  # Giả định hàm kích hoạt tuyến tính\n",
    "            delta = np.dot(deltas[idx + 1], self.weights[idx + 1].T) * derivative\n",
    "            deltas[idx] = delta\n",
    "\n",
    "        # Cập nhật trọng số và bias\n",
    "        for idx in range(len(self.weights)):\n",
    "            weight_gradient = np.dot(self.activations[idx].T, deltas[idx]) / self.num_samples\n",
    "            bias_gradient = np.sum(deltas[idx], axis=0, keepdims=True) / self.num_samples\n",
    "            self.weights[idx] -= self.learning_rate * weight_gradient\n",
    "            self.biases[idx] -= self.learning_rate * bias_gradient\n",
    "\n",
    "    def train(self, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.feed_forward()\n",
    "            loss = self.compute_loss(output, self.targets)\n",
    "            self.back_propagate()\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss}\")\n",
    "\n",
    "    def compute_loss(self, predictions, targets):\n",
    "        if self.activation_functions[-1] == 'softmax':\n",
    "            # Sử dụng hàm mất mát cross-entropy\n",
    "            epsilon = 1e-12\n",
    "            predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "            N = predictions.shape[0]\n",
    "            ce_loss = -np.sum(targets * np.log(predictions + 1e-9)) / N\n",
    "            return ce_loss\n",
    "        else:\n",
    "            # Sử dụng MSE cho các hàm kích hoạt khác\n",
    "            mse_loss = np.mean((predictions - targets) ** 2)\n",
    "            return mse_loss\n",
    "        \n",
    "# Định nghĩa các tham số mạng\n",
    "input_size = 784  # Kích thước đầu vào (ví dụ, ảnh MNIST)\n",
    "hidden_layers = [128, 64]  # Các lớp ẩn\n",
    "output_size = 10  # Số lớp đầu ra (số lớp phân loại)\n",
    "learning_rate = 0.01\n",
    "activation_functions = ['relu', 'relu', 'softmax']\n",
    "\n",
    "train_data = np.loadtxt('mnist_train.csv', delimiter= ',')\n",
    "\n",
    "# Tạo dữ liệu đầu vào và mục tiêu\n",
    "inputs = train_data[:, 1:]  # Dữ liệu đầu vào mẫu\n",
    "targets = train_data[:, 0]\n",
    "# Gán nhãn mục tiêu (one-hot encoding)\n",
    "for i in range(1000):\n",
    "    targets[i, np.random.randint(0, output_size)] = 1\n",
    "\n",
    "# Khởi tạo và huấn luyện mạng\n",
    "nn = NeuralNetwork(input_size, hidden_layers, output_size, learning_rate, activation_functions, inputs, targets)\n",
    "nn.train(epochs=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 97576.74786855133\n",
      "Epoch 101, Loss: nan\n",
      "Epoch 201, Loss: nan\n",
      "Epoch 301, Loss: nan\n",
      "Epoch 401, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hongquan\\AppData\\Local\\Temp\\ipykernel_9852\\2957714498.py:64: RuntimeWarning: overflow encountered in matmul\n",
      "  vector = vector @ weight + bias\n",
      "C:\\Users\\hongquan\\AppData\\Local\\Temp\\ipykernel_9852\\2957714498.py:64: RuntimeWarning: invalid value encountered in matmul\n",
      "  vector = vector @ weight + bias\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "symbol": "x"
         },
         "mode": "markers",
         "name": "Data Points",
         "type": "scatter",
         "x": [
          59,
          86,
          95,
          91,
          14,
          16,
          67,
          81,
          86,
          9,
          75,
          30,
          4,
          10,
          63,
          69,
          84,
          95,
          55,
          53,
          48,
          74,
          3,
          62,
          80,
          68,
          63,
          66,
          71,
          68,
          91,
          39,
          63,
          96,
          82,
          56,
          47,
          2,
          84,
          61,
          77,
          85,
          18,
          95,
          64,
          88,
          67,
          62,
          96,
          85,
          74,
          26,
          64,
          47,
          34,
          55,
          47,
          11,
          71,
          70,
          31,
          93,
          93,
          98,
          67,
          93,
          6,
          89,
          14,
          26,
          39,
          24,
          64,
          89,
          16,
          58,
          57,
          5,
          19,
          63,
          18,
          23,
          72,
          29,
          49,
          27,
          56,
          22,
          66,
          98,
          53,
          58,
          1,
          48,
          10,
          91,
          47,
          40,
          21,
          52
         ],
         "y": [
          271.8715331413415,
          432.7451484335549,
          437.68898770204095,
          401.2473410810591,
          50.51880557342632,
          100.91910155612725,
          318.28683509781087,
          364.0931540282129,
          384.7578501514164,
          59.30173130231662,
          330.92803565825284,
          129.35218500326164,
          31.05366120909676,
          20.89427078207488,
          351.90795060305487,
          289.1263068854503,
          427.73040239151214,
          474.2312107952136,
          247.29894912748324,
          248.00517229693412,
          243.68625726050965,
          390.7303313403867,
          69.76683299068966,
          323.44423309282934,
          431.3836334773824,
          347.66929867588976,
          323.4635909374389,
          360.5660819454072,
          386.36872811152864,
          383.0381674532256,
          445.3851992029208,
          226.67203482675563,
          325.23132234600934,
          498.40828624926536,
          395.8849325514327,
          259.3074884037161,
          243.34051284942737,
          26.132770267759398,
          380.95503251127167,
          310.23188930170016,
          375.3072319764832,
          435.3406882504131,
          83.71084578606055,
          435.53893408654255,
          348.1271103964115,
          431.6651805557968,
          307.4655663594174,
          338.2662599618851,
          494.7326477651642,
          468.93823753318753,
          378.05276556336247,
          135.7970665905943,
          318.9874499842179,
          260.2559729688633,
          198.1917911701757,
          270.54353009666625,
          213.21794925565567,
          57.312762655951246,
          316.40859155241634,
          343.4279139329801,
          154.2179913588729,
          480.0469168359595,
          416.3570584698144,
          528.7829365715327,
          360.3652777102397,
          467.3001264000116,
          27.09637957316822,
          491.6886557847143,
          41.88708892556809,
          88.28593531070746,
          180.4581094684285,
          116.82533543008508,
          292.1953862503292,
          459.113672075226,
          63.50451474481052,
          242.9597206185295,
          355.41875971578315,
          54.19820944182918,
          76.09173204236542,
          343.8639127005553,
          93.45740819928874,
          65.99320150020111,
          381.761556044339,
          87.9448390470013,
          225.56877558324751,
          90.3014215694298,
          306.7251039079593,
          95.38490572430852,
          322.7723380380088,
          470.3360299271792,
          252.0207800374984,
          294.9588125911794,
          29.09254989284092,
          214.74525106046647,
          35.13633618656753,
          486.85180074246296,
          275.9262542910159,
          175.97192168908578,
          115.89204495209307,
          206.56202538384676
         ]
        },
        {
         "mode": "lines",
         "name": "Regression Line",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "y": [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Define the ActivationFunc and NeuralNetwork classes\n",
    "class ActivationFunc:\n",
    "    def __init__(self, input) -> None:\n",
    "        self.input = input\n",
    "\n",
    "    def ReLu(self):\n",
    "        # return np.maximum(0, self.input)\n",
    "        return self.input\n",
    "    \n",
    "    def ReLu_derivative(self):\n",
    "        return np.where(self.input > 0, 1, 0)\n",
    "\n",
    "    def SoftMax(self):\n",
    "        exp_values = np.exp(self.input - np.max(self.input, axis=1, keepdims=True))\n",
    "        sum_exp = np.sum(exp_values, axis=1, keepdims=True)\n",
    "        return exp_values / sum_exp\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, *, number_neural_input: int, hidden_layer: tuple,\n",
    "                  number_neural_output: int, learning_rate: float, optimizer: list,\n",
    "                  layer_activation_fn: list, input: np.array, target= np.array) -> None:\n",
    "        self.number_neural_input = number_neural_input\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.number_neural_output = number_neural_output\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layer_activation_fn = layer_activation_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.input = input\n",
    "        self.target = target\n",
    "        self.len = len(input)\n",
    "\n",
    "    def __call__(self):\n",
    "        self.array = np.insert(self.hidden_layer, 0, self.number_neural_input)\n",
    "        self.array = np.append(self.array, self.number_neural_output)\n",
    "        self.error_layer = [0] * (len(self.array) - 1)\n",
    "        self.list_vectors_layer = [0] * len(self.array)\n",
    "        self.list_vectors_layer[0] = self.input\n",
    "        self.matrices_weights = [0] * (len(self.array) - 1)\n",
    "        self.matrices_biases = [0] * (len(self.array) - 1)\n",
    "\n",
    "        self.create_matrices_bias_layer()\n",
    "        self.create_matrices_weight_layer()\n",
    "\n",
    "    def create_matrices_weight_layer(self):\n",
    "        for idx, value in enumerate(self.array):\n",
    "            if idx + 1 > len(self.array) - 1:\n",
    "                break\n",
    "            else:\n",
    "                matrix_weight = np.random.randn(self.array[idx], self.array[idx+1]) / 10\n",
    "                self.matrices_weights[idx] = matrix_weight\n",
    "\n",
    "    def create_matrices_bias_layer(self):\n",
    "        for idx, num_bias in enumerate(self.array[1:]):\n",
    "            matrix_bias = np.random.randn(1, num_bias) / 10\n",
    "            self.matrices_biases[idx] = matrix_bias\n",
    "\n",
    "    def feed_forward(self):\n",
    "        vector = self.input.reshape(self.len, -1)\n",
    "        for idx, (weight, bias) in enumerate(zip(self.matrices_weights, self.matrices_biases)):\n",
    "            vector = vector @ weight + bias\n",
    "            activation_func = ActivationFunc(vector)\n",
    "            if self.layer_activation_fn[idx] == 'ReLu':\n",
    "                vector_activated = activation_func.ReLu()\n",
    "            elif self.layer_activation_fn[idx] == 'SoftMax':\n",
    "                vector_activated = activation_func.SoftMax()\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported activation function: {self.layer_activation_fn[idx]}\")\n",
    "            self.list_vectors_layer[idx + 1] = vector_activated\n",
    "            vector = vector_activated\n",
    "        return vector_activated\n",
    "    \n",
    "    def test(self, input):\n",
    "        vector = input.reshape(self.len, -1)\n",
    "        for idx, (weight, bias) in enumerate(zip(self.matrices_weights, self.matrices_biases)):\n",
    "            vector = vector @ weight + bias\n",
    "            activation_func = ActivationFunc(vector)\n",
    "            if self.layer_activation_fn[idx] == 'ReLu':\n",
    "                vector_activated = activation_func.ReLu()\n",
    "            elif self.layer_activation_fn[idx] == 'SoftMax':\n",
    "                vector_activated = activation_func.SoftMax()\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported activation function: {self.layer_activation_fn[idx]}\")\n",
    "            self.list_vectors_layer[idx + 1] = vector_activated\n",
    "            vector = vector_activated\n",
    "        return vector_activated\n",
    "    \n",
    "    def cal_error_layer(self):\n",
    "        self.error_layer[-1] = self.list_vectors_layer[-1] - self.target\n",
    "        for idx in reversed(range(len(self.error_layer) - 1)):\n",
    "            activation_input = self.list_vectors_layer[idx + 1]\n",
    "            activation_func = ActivationFunc(activation_input)\n",
    "            if self.layer_activation_fn[idx] == 'ReLu':\n",
    "                activation_derivative = activation_func.ReLu_derivative()\n",
    "            else:\n",
    "                activation_derivative = 1\n",
    "            weight_next = self.matrices_weights[idx + 1]\n",
    "            error_next = self.error_layer[idx + 1]\n",
    "            self.error_layer[idx] = (error_next @ weight_next.T) * activation_derivative\n",
    "\n",
    "    def back_prop(self):\n",
    "        for idx in reversed(range(len(self.matrices_weights))):\n",
    "            activation_prev = self.list_vectors_layer[idx]\n",
    "            error_current = self.error_layer[idx]\n",
    "            gradient_weights = activation_prev.T @ error_current\n",
    "            gradient_biases = np.sum(error_current, axis=0, keepdims=True)\n",
    "            self.matrices_weights[idx] -= self.learning_rate * gradient_weights\n",
    "            self.matrices_biases[idx] -= self.learning_rate * gradient_biases\n",
    "\n",
    "    def compute_loss(self, predictions, targets):\n",
    "        if self.layer_activation_fn[-1] == 'SoftMax':\n",
    "            epsilon = 1e-12\n",
    "            predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "            N = predictions.shape[0]\n",
    "            ce_loss = -np.sum(targets * np.log(predictions)) / N\n",
    "            return ce_loss\n",
    "        else:\n",
    "            mse_loss = np.mean((predictions - targets) ** 2)\n",
    "            return mse_loss\n",
    "\n",
    "    def train(self, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.feed_forward()\n",
    "            loss = self.compute_loss(output, self.target)\n",
    "            self.cal_error_layer()\n",
    "            self.back_prop()\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch + 1}, Loss: {loss}\")\n",
    "\n",
    "# Load the sample data\n",
    "pd_dataframe = pd.read_csv('ex1.csv')\n",
    "input_data = pd_dataframe['x'].to_numpy().reshape(1, -1)\n",
    "target_data = pd_dataframe['y'].to_numpy().reshape(1, -1)\n",
    "\n",
    "# Define network parameters\n",
    "number_neural_input = 100\n",
    "hidden_layer = (128, 64)\n",
    "number_neural_output = 100\n",
    "learning_rate = 0.01\n",
    "optimizer = []\n",
    "layer_activation_fn = ['ReLu', 'ReLu', 'ReLu']\n",
    "\n",
    "# Initialize and train the neural network\n",
    "nn = NeuralNetwork(\n",
    "    number_neural_input=number_neural_input,\n",
    "    hidden_layer=hidden_layer,\n",
    "    number_neural_output=number_neural_output,\n",
    "    learning_rate=learning_rate,\n",
    "    optimizer=optimizer,\n",
    "    layer_activation_fn=layer_activation_fn,\n",
    "    input=input_data,\n",
    "    target=target_data\n",
    ")\n",
    "\n",
    "# Initialize network parameters\n",
    "nn()\n",
    "\n",
    "# Train the model\n",
    "nn.train(epochs=500)\n",
    "\n",
    "# Generate the plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add scatter plot for the original data points\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=pd_dataframe['x'],  \n",
    "        y=pd_dataframe['y'],  \n",
    "        mode='markers',  \n",
    "        marker=dict(symbol='x'),  \n",
    "        name='Data Points'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate a range of x values and predict using the trained model\n",
    "x_range = np.linspace(1, 100, 100)\n",
    "y_range = nn.test(x_range.reshape(1, -1)).reshape(-1,)\n",
    "\n",
    "# Add regression line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_range,  \n",
    "        y=y_range,  \n",
    "        mode='lines',  \n",
    "        name='Regression Line'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
